{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.0     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n"
     ]
    }
   ],
   "source": [
    "libraries = c(\"dplyr\", \"tidyverse\", \"magrittr\")\n",
    "for(x in libraries) {library(x,character.only=TRUE,warn.conflicts=FALSE,quietly=TRUE)}\n",
    "theme_set(theme_bw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### setting\n",
    "start_date <- as.Date(\"2022-04-17\") ## symptom onset date of the initial case in the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data with depletion effect\n",
    "read.csv(\"../data/input_WHO_backproj.csv\") -> df_input\n",
    "df_input$date <- as.Date(df_input$date)\n",
    "df_input$date_import <- as.Date(df_input$date_import)\n",
    "censor_import <- max(df_input$date) ## for countries without any importation\n",
    "\n",
    "## excluding the endemic countries (along with the UK)\n",
    "df_input %<>% rename(censor=censoring, country=location) %>%\n",
    "mutate(date_imp=case_when(censor==1~censor_import, censor==0~date_import)) %>%\n",
    "filter(!(country %in% c(\"Cameroon\",\"Liberia\",\"Central African Republic\",\"Nigeria\",\n",
    "                         \"Congo\",\"Congo, Democratic Republic of the\",\"Ghana\",\"Palestine, State of\",\n",
    "                         \"United Kingdom\")))\n",
    "\n",
    "df_input %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> df_input_all\n",
    "\n",
    "## regional specific data\n",
    "data_list <- list()\n",
    "df_input %>% filter(region == c(\"Europe\")) %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list[[1]]\n",
    "\n",
    "df_input %>% filter(region == c(\"Africa\")) %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list[[2]]\n",
    "\n",
    "df_input %>% filter(region == c(\"Americas\")) %>%  dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list[[3]]\n",
    "\n",
    "df_input %>% filter(region == c(\"Asia\")) %>% filter(!sub_region %in% c(\"Central Asia\", \"Western Asia\")) %>% \n",
    "dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list[[4]]\n",
    "\n",
    "df_input %>% filter(sub_region %in% c(\"Central Asia\", \"Western Asia\")) %>% \n",
    "dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list[[5]]\n",
    "\n",
    "df_input %>% filter(region == c(\"Oceania\")) %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list[[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data without depletion effect\n",
    "read.csv(\"../data/input_WHO_backproj_counter.csv\") -> df_input_counter\n",
    "df_input_counter$date <- as.Date(df_input_counter$date)\n",
    "df_input_counter$date_import <- as.Date(df_input_counter$date_import)\n",
    "\n",
    "## excluding the endemic countries (along with the UK)\n",
    "df_input_counter %<>% rename(censor=censoring, country=location) %>%\n",
    "mutate(date_imp=case_when(censor==1~censor_import, censor==0~date_import)) %>% \n",
    "filter(!(country %in% c(\"Cameroon\",\"Liberia\",\"Central African Republic\",\"Nigeria\",\n",
    "                         \"Congo\",\"Congo, Democratic Republic of the\",\"Ghana\",\"Palestine, State of\",\n",
    "                         \"United Kingdom\")))\n",
    "\n",
    "df_input_counter %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> df_input_counter_all\n",
    "\n",
    "## regional specific data\n",
    "data_list_counter <- list()\n",
    "df_input_counter %>% filter(region == c(\"Europe\")) %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list_counter[[1]]\n",
    "\n",
    "df_input_counter %>% filter(region == c(\"Africa\")) %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list_counter[[2]]\n",
    "\n",
    "df_input_counter %>% filter(region == c(\"Americas\")) %>%dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list_counter[[3]]\n",
    "\n",
    "df_input_counter %>% filter(region == c(\"Asia\")) %>% filter(!sub_region %in% c(\"Central Asia\", \"Western Asia\")) %>% \n",
    "dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list_counter[[4]]\n",
    "\n",
    "df_input_counter %>% filter(sub_region %in% c(\"Central Asia\", \"Western Asia\")) %>% \n",
    "dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list_counter[[5]]\n",
    "\n",
    "df_input_counter %>% filter(region == c(\"Oceania\")) %>% dplyr::select(date, country, F_i, date_imp, censor) %>% \n",
    "filter(date >= start_date) %>% arrange(date, country) -> data_list_counter[[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### likelihood without random effect\n",
    "LogL_i <- function(data, country_i){\n",
    "    data_i <- data %>% filter(country==country_i)\n",
    "    date_start_i <- data_i[1,1]\n",
    "    date_import_i <- data_i[length(data_i[,1]), 4]\n",
    "    surv_days_i <- as.numeric(date_import_i - date_start_i)+1\n",
    "    F_i_vec <- data_i$F_i\n",
    "    cens_i <- data_i[1,5] \n",
    "    \n",
    "    function(alpha){\n",
    "        return(\n",
    "            (1-cens_i) * (log(alpha * F_i_vec[surv_days_i]) + (-sum(alpha * F_i_vec[1:surv_days_i]))) + \n",
    "            cens_i * (-sum(alpha * F_i_vec[1:surv_days_i])) \n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "LogL_full <- function(data, country_list){\n",
    "  function(alpha){\n",
    "      return(sum(sapply(country_list, FUN = function(x){LogL_i(data=data, country_i = x)(alpha=alpha)})))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MLE for the model with depletion effect\n",
    "## with global scaling factor\n",
    "options(warn=-1)\n",
    "optim(fn=LogL_full(data=df_input_all, country_list=(unique(df_input_all$country))), \n",
    "      par=c(0.001), method=\"Brent\", lower=(0), upper=(1000), control = list(fnscale = -1, maxit=1000000)) -> est_all\n",
    "\n",
    "## with regional specific scaling factors (separate MLE by region)\n",
    "par_list <- list(); value_list <- list()\n",
    "for(i in 1:length(data_list)){\n",
    "    optim(fn=LogL_full(data=data_list[[i]], country_list=(unique(data_list[[i]]$country))), \n",
    "          par=c(0.001), method=\"Brent\", lower=(0), upper=(1000), control = list(fnscale = -1, maxit=1000000)) -> est\n",
    "    est$par -> par_list[[i]]; est$value -> value_list[[i]]\n",
    "    \n",
    "}\n",
    "\n",
    "#### MLE for the model without depletion effect\n",
    "## with global scaling factor\n",
    "optim(fn=LogL_full(data=df_input_counter_all, country_list=(unique(df_input_counter_all$country))), \n",
    "      par=c(0.001), method=\"Brent\", lower=(0), upper=(1000), \n",
    "      control = list(fnscale = -1, maxit=1000000)) -> est_all_counter\n",
    "\n",
    "## with regional specific scaling factors (separate MLE by region)\n",
    "par_list_counter <- list(); value_list_counter <- list()\n",
    "for(i in 1:length(data_list_counter)){\n",
    "    optim(fn=LogL_full(data=data_list_counter[[i]], country_list=(unique(data_list_counter[[i]]$country))), \n",
    "          par=c(0.001), method=\"Brent\", lower=(0), upper=(1000), \n",
    "          control = list(fnscale = -1, maxit=1000000)) -> est\n",
    "    est$par -> par_list_counter[[i]]; est$value -> value_list_counter[[i]]\n",
    "    \n",
    "}\n",
    "options(warn=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### likelihood with random effect and global scaling factor\n",
    "LogL_i_random <- function(data, country_i){\n",
    "    data_i <- data %>% filter(country==country_i)\n",
    "    date_start_i <- data_i[1,1]\n",
    "    date_import_i <- data_i[length(data_i[,1]), 4]\n",
    "    surv_days_i <- as.numeric(date_import_i - date_start_i)+1\n",
    "    F_i_vec <- data_i$F_i\n",
    "    cens_i <- data_i[1,5] \n",
    "    \n",
    "    function(alpha, theta){\n",
    "        return(\n",
    "            (1-cens_i) * \n",
    "            (alpha + log(F_i_vec[surv_days_i]) +  \n",
    "            -(theta+1)/theta * log(1+theta*sum(exp(alpha)*F_i_vec[1:surv_days_i]))) +\n",
    "            cens_i * -1/theta * log(1+theta*sum(exp(alpha)*F_i_vec[1:surv_days_i]))\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "LogL_full_random <- function(data, country_list){\n",
    "  function(params){\n",
    "    return(sum(sapply(country_list, \n",
    "                      FUN = function(x){LogL_i_random(data=data, country_i = x)(params[1], params[2])})))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MLE for the model with depletion effect\n",
    "## with global scaling factor\n",
    "options(warn=-1)\n",
    "optim(fn=LogL_full_random(data=df_input_all, country_list=(unique(df_input_all$country))), \n",
    "      par=c(log(0.001), 1), method=\"BFGS\", control = list(fnscale = -1, maxit=1000000)) -> est_all_random\n",
    "\n",
    "\n",
    "#### MLE for the model without depletion effect\n",
    "## with global scaling factor\n",
    "optim(fn=LogL_full_random(data=df_input_counter_all, country_list=(unique(df_input_counter_all$country))), \n",
    "      par=c(log(0.001), 1), method=\"BFGS\", control = list(fnscale = -1, maxit=1000000)) -> est_all_counter_random\n",
    "\n",
    "options(warn=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$par</dt>\n",
       "\t\t<dd><style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-5.8769209527212</li><li>-8.45710191406609</li><li>-5.75880566737479</li><li>-8.13359302573551</li><li>-6.90886014811513</li><li>-5.20163310404633</li><li>0.717408009474424</li></ol>\n",
       "</dd>\n",
       "\t<dt>$value</dt>\n",
       "\t\t<dd>-507.10763554997</dd>\n",
       "\t<dt>$counts</dt>\n",
       "\t\t<dd><style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>function</dt><dd>146</dd><dt>gradient</dt><dd>100</dd></dl>\n",
       "</dd>\n",
       "\t<dt>$convergence</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$message</dt>\n",
       "\t\t<dd>NULL</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$par] \\begin{enumerate*}\n",
       "\\item -5.8769209527212\n",
       "\\item -8.45710191406609\n",
       "\\item -5.75880566737479\n",
       "\\item -8.13359302573551\n",
       "\\item -6.90886014811513\n",
       "\\item -5.20163310404633\n",
       "\\item 0.717408009474424\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$value] -507.10763554997\n",
       "\\item[\\$counts] \\begin{description*}\n",
       "\\item[function] 146\n",
       "\\item[gradient] 100\n",
       "\\end{description*}\n",
       "\n",
       "\\item[\\$convergence] 0\n",
       "\\item[\\$message] NULL\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$par\n",
       ":   1. -5.8769209527212\n",
       "2. -8.45710191406609\n",
       "3. -5.75880566737479\n",
       "4. -8.13359302573551\n",
       "5. -6.90886014811513\n",
       "6. -5.20163310404633\n",
       "7. 0.717408009474424\n",
       "\n",
       "\n",
       "\n",
       "$value\n",
       ":   -507.10763554997\n",
       "$counts\n",
       ":   function\n",
       ":   146gradient\n",
       ":   100\n",
       "\n",
       "\n",
       "$convergence\n",
       ":   0\n",
       "$message\n",
       ":   NULL\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$par\n",
       "[1] -5.876921 -8.457102 -5.758806 -8.133593 -6.908860 -5.201633  0.717408\n",
       "\n",
       "$value\n",
       "[1] -507.1076\n",
       "\n",
       "$counts\n",
       "function gradient \n",
       "     146      100 \n",
       "\n",
       "$convergence\n",
       "[1] 0\n",
       "\n",
       "$message\n",
       "NULL\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### likelihood with random effect and regional specific scaling factor\n",
    "logL_random_region <- function(params){\n",
    "    llk_all <- rep(0, length(data_list))\n",
    "    \n",
    "    for(k in 1:length(data_list)){\n",
    "        llk <- rep(0, length(unique(data_list[[k]]$country)))\n",
    "        \n",
    "        for(g in 1:length(unique(data_list[[k]]$country))){\n",
    "            data_i <- data_list[[k]] %>% filter(country==unique(data_list[[k]]$country)[g])\n",
    "            date_start_i <- data_i[1,1]\n",
    "            date_import_i <- data_i[length(data_i[,1]), 4]\n",
    "            surv_days_i <- as.numeric(date_import_i - date_start_i)+1\n",
    "            F_i_vec <- data_i$F_i\n",
    "            cens_i <- data_i[1,5] \n",
    "            \n",
    "            llk[g] <- (1-cens_i) * \n",
    "            (params[k] + log(F_i_vec[surv_days_i]) +  \n",
    "             -(params[7]+1)/params[7] * log(1+params[7]*sum(exp(params[k])*F_i_vec[1:surv_days_i]))) +\n",
    "            cens_i * -1/params[7] * log(1+params[7]*sum(exp(params[k])*F_i_vec[1:surv_days_i]))\n",
    "        }\n",
    "        llk_all[k] <- sum(llk)\n",
    "    }\n",
    "    return(sum(llk_all))\n",
    "}\n",
    "\n",
    "options(warn=-1)\n",
    "do.call(rbind, par_list) %>% as.vector() -> initial_list\n",
    "optim(fn=logL_random_region, par=c(initial_list, 0.5), \n",
    "      method=\"BFGS\", control = list(fnscale = -1, maxit=1000000)) -> est_random_region\n",
    "options(warn=0)\n",
    "\n",
    "est_random_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### likelihood with random effect and regional specific scaling factor without depletion effect\n",
    "logL_random_region_counter <- function(params){ \n",
    "    llk_all <- rep(0, length(data_list_counter))\n",
    "    \n",
    "    for(k in 1:length(data_list_counter)){\n",
    "        llk <- rep(0, length(unique(data_list_counter[[k]]$country)))\n",
    "        \n",
    "        for(g in 1:length(unique(data_list_counter[[k]]$country))){\n",
    "            data_i <- data_list_counter[[k]] %>% filter(country==unique(data_list_counter[[k]]$country)[g])\n",
    "            date_start_i <- data_i[1,1]\n",
    "            date_import_i <- data_i[length(data_i[,1]), 4]\n",
    "            surv_days_i <- as.numeric(date_import_i - date_start_i)+1\n",
    "            F_i_vec <- data_i$F_i\n",
    "            cens_i <- data_i[1,5] \n",
    "            \n",
    "            llk[g] <- (1-cens_i) * \n",
    "            (params[k] + log(F_i_vec[surv_days_i]) +  \n",
    "             -(params[7]+1)/params[7] * log(1+params[7]*sum(exp(params[k])*F_i_vec[1:surv_days_i]))) +\n",
    "            cens_i * -1/params[7] * log(1+params[7]*sum(exp(params[k])*F_i_vec[1:surv_days_i]))\n",
    "        }\n",
    "        llk_all[k] <- sum(llk)\n",
    "    }\n",
    "    return(sum(llk_all))\n",
    "}\n",
    "\n",
    "options(warn=-1)\n",
    "do.call(rbind, par_list_counter) %>% as.vector() -> initial_list\n",
    "optim(fn=logL_random_region_counter, par=c(initial_list, 0.5), \n",
    "      method=\"BFGS\", control = list(fnscale = -1, maxit=1000000)) -> est_random_counter_region\n",
    "options(warn=0)\n",
    "\n",
    "est_random_counter_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(est_all, \"original_global.rds\")\n",
    "saveRDS(value_list, \"original_counter.rds\")\n",
    "\n",
    "saveRDS(est_all_counter, \"original_region.rds\")\n",
    "saveRDS(value_list_counter, \"original_region.rds_counter\")\n",
    "\n",
    "saveRDS(est_all_random, \"random_global.rds\")\n",
    "saveRDS(est_all_counter_random, \"random_global_counter.rds\")\n",
    "\n",
    "saveRDS(est_random_region, \"random_region.rds\")\n",
    "saveRDS(est_random_counter_region, \"random_region_counter.rds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
